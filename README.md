<p style="clear"><a href="https://github.com/MXGray/VIsION/blob/master/AnimatedVIsIONLogo_1920x1080.gif" target="_blank"><img src="https://github.com/MXGray/VIsION/blob/master/AnimatedVIsIONLogo_1920x1080.gif" border="0" alt="Animated VIsION Logo: This is an image of a closed camera lens that opens up to show the word VIsION and closes back again, in a loop." title="Animated VIsION Logo: This is an image of a closed camera lens that opens up to show the word VIsION and closes back again, in a loop." width="480" height="270" align="left" HSPACE="30" VSPACE="30" /></a><br><br><b>VIsION</b><br><b>Wearable AI for the Blind</b><br><br><br></p>

<p style="clear">This aims to provide visually impaired users with an affordable solution for their day-to-day activities.</p>

<p style="clear">Being completely blind myself, this can help me know the objects in front of me, their placement and the distance of my central focus, with or without an Internet connection.</p>

<p style="clear">This video shows the target objectives of this project:  https://www.youtube.com/tv#/watch?v=NIZj7IW-FDk</p>

<p style="clear">A wearable form factor will free up both our hands and give us optimum mobility.</p>

<p style="clear"><ul><li>  This is unlike the difficulty we experience when we need to take out our smartphones from time to time while walking around and holding our white canes;</li><br>
<li>  This is also much better than straining our arms, necks and backs just to capture what's in front of us like a paper document or a set of physical objects; and</li><br>
<li>  I also want a solution that won't require me to take out my smartphone while walking around, especially here in the Philippines where I can be victimized by violent crooks who are out to steal expensive smartphones from random passersby (my blindness is due to a senseless incident of violence 15 years ago).</li></ul></p>
<br>

<table border="1" cellpadding="10">
<tr>
<th>RAW PROTOTYPE</th>
<th>3D PRINTED PROTOTYPE</th>
</tr>
<tr>
<td><B>Front (Worn by User</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledFrontView_BlindUserWearingVIsIONGlasses.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledFrontView_BlindUserWearingVIsIONGlasses.png" width="372" height="266" alt="Front and center photo of blind user wearing VIsION glasses with labels of already tested 8 megapixel camera, noise-cancelling mic and sonar sensor." title="Front and center photo of blind user wearing VIsION glasses with labels of already tested 8 megapixel camera, noise-cancelling mic and sonar sensor." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Front Right (Worn by User)</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledFrontRightView_BlindUserWearingVIsIONGlasses.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledFrontRightView_BlindUserWearingVIsIONGlasses.png" width="372" height="266" alt="Front right photo of blind user wearing VIsION glasses with labels of already tested 8 megapixel camera, noise-cancelling mic, sonar sensor and wireless earbud." title="Front right photo of blind user wearing VIsION glasses with labels of already tested 8 megapixel camera, noise-cancelling mic, sonar sensor and wireless earbud." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Top (RPi Version)</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledFullTopView_RaspberryPiWVersion.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledFullTopView_RaspberryPiWVersion.png" width="372" height="266" alt="Full top photo of VIsION glasses (RPi version) with labels of already integrated 8 megapixel camera, noise-cancelling mic, sonar sensor, wireless earbud and tiny single board Raspberry Pi Zero W computer, along with labels of soon-to-be implemented haptic discs, additional sonar sensors and bone-conducting speaker modules." title="Full top photo of VIsION glasses (RPi version) with labels of already integrated 8 megapixel camera, noise-cancelling mic, sonar sensor, wireless earbud and tiny single board Raspberry Pi Zero W computer, along with labels of soon-to-be implemented haptic discs, additional sonar sensors and bone-conducting speaker modules." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Top (ICS Version)</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledFullTopView_IntelComputeStickVersion.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledFullTopView_IntelComputeStickVersion.png" width="372" height="266" alt="Full top photo of VIsION glasses (ICS version) with labels of already integrated 8 megapixel camera, noise-cancelling mic, sonar sensor, wireless earbud and small Intel Compute Stick pocket PC, along with labels of soon-to-be implemented haptic discs, additional sonar sensors and bone-conducting speaker modules." title="Full top photo of VIsION glasses (ICS version) with labels of already integrated 8 megapixel camera, noise-cancelling mic, sonar sensor, wireless earbud and small Intel Compute Stick pocket PC, along with labels of soon-to-be implemented haptic discs, additional sonar sensors and bone-conducting speaker modules." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Outer Front</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledFrontView.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledFrontView.png" width="372" height="266" alt="Front and center photo of VIsION glasses with labelled electronic components." title="Front and center photo of VIsION glasses with labelled electronic components." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Inner Front Side</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledInnerCenterView.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledInnerCenterView.png" width="372" height="266" alt="Inner front side photo of VIsION glasses with labelled electronic components." title="Inner front side photo of VIsION glasses with labelled electronic components." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Outer Left Arm</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledOuterLeftArmView.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledOuterLeftArmView.png" width="372" height="266" alt="Outer left arm photo of VIsION glasses with labelled electronic components." title="Outer left arm photo of VIsION glasses with labelled electronic components." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Inner Left Arm</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledInnerLeftArmView.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledInnerLeftArmView.png" width="372" height="266" alt="Inner left arm photo of VIsION glasses with labelled electronic components." title="Inner left arm photo of VIsION glasses with labelled electronic components." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Outer Right Arm</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledOuterRightArmView.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledOuterRightArmView.png" width="372" height="266" alt="Outer right arm photo of VIsION glasses with labelled electronic components." title="Outer right arm photo of VIsION glasses with labelled electronic components." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Inner Right Arm</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledInnerRightArmView.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledInnerRightArmView.png" width="372" height="266" alt="Inner right arm photo with labelled electronic components." title="Inner right arm photo with labelled electronic components." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td><B>Bone-Conducting Speaker Placement</B><br><a href="https://github.com/MXGray/VIsION/blob/master/LabelledBoneConductingSpeakerPlacementView.png" target="_blank"><img style="display:block;" border="0" src="https://github.com/MXGray/VIsION/blob/master/LabelledBoneConductingSpeakerPlacementView.png" width="372" height="266" alt="Left and right arm photo of VIsION glasses with labelled placement areas for pair of tiny bone-conducting speaker modules." title="Left and right arm photo of VIsION glasses with labelled placement areas for pair of tiny bone-conducting speaker modules." /></a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
</table>
<br>

<p style="clear">For offline multiple object detection and recognition, I used the following:</p>
<p style="clear"><ul><li>  A set of fine-tuned object detection and recognition, person / face detection and age / gender estimation AI models; along with</li><br>
<li>  Custom scripts for distance estimation through an ultrasonic sensor and clockface object placement description through image post-processing.</li></ul></p>

<p style="clear">I also used services from Microsoft Cognitive Services (Computer Vision & Batch Read File APIs) and Cloudsight to integrate online object recognition, visual scene description and OCR (optical character recognition) functions.</p>

<p style="clear"><b>Note:</b>  Release v0.0.2 is updated with OCR functions ...</p>

<p style="clear">Audible descriptions are through the Microsoft SAPI5 engine. Meanwhile, remote manual visual assistance is through Skype.</p>

<p style="clear">My device also serves as my pocket computer, which is very useful for me when I'm up and about.</p>

<p style="clear">I'm still working on offline OCR functions, mainly document detection and super-resolution among other image pre and post-processing functions. Plus:</p>
<p style="clear"><ul><li>  I'll continue to test and improve my trained / fine-tuned Tesseract model; and</li><br>
  <li>  I'll further optimize the hardware components and software features of my project.</li></ul></p>

<p style="clear">Also, this live video is for San Francisco Lighthouse for the Blind's annual Holman Prize 2019 competition (ongoing as of this writing):  https://www.youtube.com/tv#/watch?v=A5O-R_WJDgQ</p>
<p style="clear"><ul><li>  This project was hand-picked this April 2019 as a semifinalist out of more than 110 participants across 6 continents.</li></ul></p>
  
